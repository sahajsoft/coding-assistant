{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import os\n",
    "repo_url = 'https://github.com/sahajsoft/Pravarthan'\n",
    "# clone the repo if it doesn't exist\n",
    "expanded_path = os.path.expanduser('~/Pravarthan')\n",
    "\n",
    "if not os.path.exists(expanded_path):\n",
    "    repo = git.Repo.clone_from(repo_url, expanded_path)\n",
    "else:\n",
    "    repo = git.Repo(expanded_path)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding detection failed for file '/Users/joey/Pravarthan/SahajIntranet/decorators.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/sales/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/sales/migrations/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/sales/serializers/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/deploy/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/projects/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/projects/migrations/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/projects/tests/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/projects/serializers/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/projects/controllers/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/projects/handlers/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/projects/services/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/functional_tests/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/s3service/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/people/migrations/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/people/sadhak_migration/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/people/sadhak_migration/tests/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/people/serializers/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/people/services/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/xpensify/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/xpensify/tests/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/xpensify/services/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/delivery/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/delivery/migrations/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/delivery/tests/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/delivery/tests/serializers/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/delivery/tests/controllers/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/delivery/tests/services/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/delivery/permissions/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/delivery/serializers/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/delivery/controllers/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/delivery/services/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/delivery/reports/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/delivery/reports/timesheet_hours_vs_invoiced_efforts/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/api/models.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/api/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/api/admin.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/api/migrations/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/api/controllers/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/api/services/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/timesheet/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/timesheet/migrations/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/timesheet/serializers/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/timesheet/controllers/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/timesheet/handlers/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/timesheet/services/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/fmv/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/fmv/migrations/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/base/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/base/migrations/__init__.py'.\n",
      "Encoding detection failed for file '/Users/joey/Pravarthan/base/permissions/__init__.py'.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "import chardet\n",
    "import os\n",
    "\n",
    "text = \"\"\n",
    "accepted_file_extensions = [\".py\"]\n",
    "\n",
    "def read_file_contents(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        encoding = result['encoding']\n",
    "        if encoding:\n",
    "            try:\n",
    "                return raw_data.decode(encoding)\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"UnicodeDecodeError: Unable to decode file '{file_path}' with detected encoding '{encoding}'.\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Encoding detection failed for file '{file_path}'.\")\n",
    "            return None\n",
    "        \n",
    "for root, dirs, files in os.walk(expanded_path):\n",
    "    for file_name in files:\n",
    "        _, ext = os.path.splitext(file_name)\n",
    "        if(ext in accepted_file_extensions):\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            # Read and print contents of each file\n",
    "            file_contents = read_file_contents(file_path)\n",
    "            if file_contents is not None:            \n",
    "                text+= file_contents\n",
    "                text+= \"\\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_nodes_from_documents in module llama_index.core.node_parser.interface:\n",
      "\n",
      "get_nodes_from_documents(documents: Sequence[llama_index.core.schema.Document], show_progress: bool = False, **kwargs: Any) -> List[llama_index.core.schema.BaseNode] method of llama_index.core.node_parser.text.code.CodeSplitter instance\n",
      "    Parse documents into nodes.\n",
      "\n",
      "    Args:\n",
      "        documents (Sequence[Document]): documents to parse\n",
      "        show_progress (bool): whether to show progress bar\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joey/Library/Caches/pypoetry/virtualenvs/coding-assistant-JkLEjshP-py3.12/lib/python3.12/site-packages/tree_sitter/__init__.py:36: FutureWarning: Language(path, name) is deprecated. Use Language(ptr, name) instead.\n",
      "  warn(\"{} is deprecated. Use {} instead.\".format(old, new), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5ecf5fd0be4ca89cf2102065f416a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.node_parser import CodeSplitter\n",
    "from tree_sitter_languages import get_language, get_parser\n",
    "\n",
    "\n",
    "# print(help(CodeSplitter))\n",
    "\n",
    "nodes = []\n",
    "\n",
    "node_parser = CodeSplitter(language=\"python\", chunk_lines = 100, chunk_lines_overlap = 15, max_chars = 1500)\n",
    "split_text = node_parser.split_text(text)\n",
    "# print(dir(node_parser))\n",
    "print(help(node_parser.get_nodes_from_documents))\n",
    "nodes = node_parser.get_nodes_from_documents(\n",
    "    [Document(text=text)], show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2316\n",
      "import os, django\n",
      "\n",
      "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"SahajIntranet.settings\")\n",
      "django.setup()\n",
      "\n",
      "from openpyxl import load_workbook\n",
      "import sys\n",
      "from people.models import Member\n",
      "from projects.models import Project\n",
      "from timesheet.models import TimeCell, TimeCellRow\n",
      "\n",
      "import pandas as pd\n",
      "from datetime import datetime\n",
      "\n",
      "time_row = {}\n",
      "Node ID: 07173f6a-d8a5-4c79-abf0-432c1bd731ad\n",
      "Text: import os, django\n",
      "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\",\n",
      "\"SahajIntranet.settings\") django.setup()  from openpyxl import\n",
      "load_workbook import sys from people.models import Member from\n",
      "projects.models import Project from timesheet.models import TimeCell,\n",
      "TimeCellRow  import pandas as pd from datetime import datetime\n",
      "time_row = {}\n"
     ]
    }
   ],
   "source": [
    "print(len(split_text))\n",
    "print(split_text[0])\n",
    "print(nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading... 1.2953367875647668%%failed to generate embedding for APP_ENV == RUNNER:\n",
      "    # general settings\n",
      "    DEBUG = True\n",
      "    ADMINS = (('Administrator', 'rohiban@gmail.com'),)\n",
      "    MANAGERS = ADMINS\n",
      "    BASE_URL = 'https://qa-internal.sahaj.ai'\n",
      "\n",
      "    # cookies\n",
      "    CSRF_COOKIE_SECURE = True\n",
      "    CSRF_COOKIE_HTTPONLY = True\n",
      "\n",
      "    X_FRAME_OPTIONS = 'DENY'\n",
      "\n",
      "    # security settings\n",
      "    ALLOWED_HOSTS = ['.sahaj.ai']\n",
      "    SECRET_KEY = env.str('SECRET_KEY')\n",
      "\n",
      "    # to check the validity of the authtoken\n",
      "    TOKEN_VALIDATE_API_ENDPOINT = 'https://pravarthan.sahaj.ai/api/v1/decode'\n",
      "    TOKEN_VALIDATE_SECRET = env.str('TOKEN_VALIDATE_SECRET')\n",
      "    SYSTEM_TOKEN = env.str('SYSTEM_TOKEN')\n",
      "    # database settings\n",
      "    # https://docs.djangoproject.com/en/1.8/ref/settings/#databases\n",
      "    DATABASES = {\n",
      "        'default': {\n",
      "            'ENGINE': 'django.db.backends.postgresql_psycopg2',\n",
      "            'NAME': env.str('POSTGRES_DB'),\n",
      "            'USER': env.str('POSTGRES_USER'),\n",
      "            'PASSWORD': env.str('DB_PASSWORD'),\n",
      "            'HOST': env.str('DB_HOST'),\n",
      "            'PORT': env.str('DB_PORT'),\n",
      "        }\n",
      "    }\n",
      "\n",
      "    # Google Drive folders' ids\n",
      "    GDRIVE_INVOICE_FOLDER = '0B3xNiF0o2ClQTlRnTVE4aDhCODg'\n",
      "    GDRIVE_CONTRACT_FOLDER = '0B3xNiF0o2ClQRWFwaW4ydUR6NUE'\n",
      "\n",
      "    # PDF generator - libreoffice\n",
      "    PDF_CONVERTOR_COMMAND = 'unoconv'\n",
      "    PDF_CONVERTOR_CONNECTION = ''\n",
      "    PDF_CONVERTOR_PARAMS = ['--format=pdf', '--output']\n",
      "\n",
      "    ALLOW_INTERACTION_WITH_GOOGLE = False\n",
      "\n",
      "    SERVICE_ACCOUNT_KEY_LOCATION = None\n",
      "\n",
      "# following settings are for Production environment\n",
      "if A: failed to generate embedding\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'response' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 40\u001b[0m\n\u001b[1;32m     33\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(split_text):\n\u001b[1;32m     36\u001b[0m     embedding_i \u001b[38;5;241m=\u001b[39m wvc\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataObject(\n\u001b[1;32m     37\u001b[0m         properties\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m: value,\n\u001b[1;32m     39\u001b[0m         },\n\u001b[0;32m---> 40\u001b[0m         vector\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[43mgen_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(embedding_i)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Print the loading percentage\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 30\u001b[0m, in \u001b[0;36mgen_embeddings\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed to generate embedding for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embedding\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'response' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import weaviate\n",
    "import weaviate.classes.config as wc\n",
    "import weaviate.classes as wvc\n",
    "import sys\n",
    "\n",
    "embedding_model = \"nomic-embed-text\"\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "if not client.collections.exists(name = 'test'):\n",
    "    client.collections.create(name = 'test')\n",
    "\n",
    "collection = client.collections.get('test')\n",
    "\n",
    "# class_obj = {\"class\": \"DocumentSearch\", \"vectorizer\": \"none\"}\n",
    "# client.schema.create_class(class_obj)\n",
    "\n",
    "\"\"\"\n",
    "A schema is defined, creating a custom class named “DocumentSearch”. This specific name doesn’t matter, \n",
    "but acts as an identifier for Weaviate, as you’ll see how we reference it later. \n",
    "The vectorizer is set to “none” since the vectorization is done externally using our embedding model.\n",
    "\"\"\"\n",
    "\n",
    "def gen_embeddings(value):\n",
    "    try:\n",
    "        response = ollama.embeddings(model=embedding_model, prompt=value)\n",
    "    except Exception as e:\n",
    "        print(f\"failed to generate embedding for {value}: {e}\")\n",
    "    embedding = response[\"embedding\"]\n",
    "    return embedding\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for i, value in enumerate(split_text):\n",
    "    embedding_i = wvc.data.DataObject(\n",
    "        properties={\n",
    "            'message': value,\n",
    "        },\n",
    "        vector=list(gen_embeddings(value))\n",
    "    )\n",
    "    embeddings.append(embedding_i)\n",
    "    # Print the loading percentage\n",
    "    print(f\"\\rLoading... {(i+1)*100/len(split_text)}%\", end=\"\")\n",
    "    # Flush the output buffer to ensure the text is printed immediately\n",
    "    sys.stdout.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.is_ready())\n",
    "print(client.is_connected())\n",
    "print(dir(client))\n",
    "\n",
    "print(help(collection.data.insert_many))\n",
    "collection.data.insert_many(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = collection.query.near_vector(\n",
    "    near_vector=gen_embeddings('''How can I get all active members'''),\n",
    "    limit=15,\n",
    "    return_metadata=wvc.query.MetadataQuery(certainty=True)\n",
    ")\n",
    "\n",
    "retrieved_messages = [o.properties['message'] for o in retrieved_docs.objects]\n",
    "\n",
    "[print(f\"{i}\\n\\n\") for i in retrieved_messages]\n",
    "\n",
    "print(retrieved_messages[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
